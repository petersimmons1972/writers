# Pattern Extraction Methodology

**Purpose**: Transform authentic writing samples into actionable pattern libraries that enable voice replication.

**Philosophy**: Patterns must be **observable, measurable, and actionable**. "Sounds like Pyle" must become "uses X% one-sentence paragraphs and compound 'and' chains."

---

## The Four-Layer Extraction System

### Layer 1: Structural Patterns (What can you count?)

**Objective**: Quantify the mechanics of their prose.

**Measurements to take:**

1. **Sentence Length Analysis**
   ```
   For each sample:
   - Count total sentences
   - Measure each sentence length (word count)
   - Calculate: average, median, min, max, standard deviation
   - Identify fragments (< 5 words)
   - Identify compound sentences (> 30 words)
   - Calculate fragment % and compound %
   ```

2. **Paragraph Structure**
   ```
   For each sample:
   - Count total paragraphs
   - Count sentences per paragraph
   - Calculate: one-sentence paragraph %
   - Calculate: average paragraph length
   - Note paragraph length variance
   ```

3. **Rhythm Patterns**
   ```
   - Map sentence length sequences (e.g., short-short-long-short)
   - Identify repeated patterns
   - Note use of fragments for emphasis
   - Document rhythm breaks (sudden length changes)
   ```

4. **Opening Techniques**
   ```
   For each sample:
   - How do they start? (action, dialogue, observation, reflection)
   - Length of opening sentence
   - Opening paragraph structure
   - Time to establish location/context
   ```

5. **Closing Techniques**
   ```
   For each sample:
   - How do they end? (anticlimax, summary, reflection, action)
   - Length of closing sentence/paragraph
   - Presence of resolution vs. ambiguity
   - Emotional register of ending
   ```

6. **Transitional Devices**
   ```
   - How do they move between ideas?
   - Use of time markers ("Around 3 AM", "Later")
   - Use of paragraph breaks for scene changes
   - Transitional phrases vs. hard cuts
   ```

**Tools:**
- Word processor word count
- Manual sentence counting
- Spreadsheet for calculations
- Pattern frequency tracking

**Output**: Structural profile with quantitative data
```markdown
## Structural Profile: [Writer Name]

**Sentence Length** (based on N samples):
- Average: X words
- Range: Y-Z words
- Fragments (<5 words): X%
- Compounds (>30 words): Y%
- Standard deviation: Z (high/low variance)

**Paragraph Structure**:
- Average sentences per paragraph: X
- One-sentence paragraphs: Y%
- Paragraph length variance: High/Medium/Low

**Common Rhythm Patterns**:
1. [short-short-long pattern in 60% of samples]
2. [fragment for emphasis after long exposition]
3. [compound sentence chains when witnessing action]

**Opening Technique** (most common):
- Physical observation (70% of samples)
- Time/location anchor (80% of samples)
- Average opening sentence length: X words

**Closing Technique** (most common):
- Anticlimax (60% of samples)
- Unresolved ambiguity (40% of samples)
- Never: summary statements, moral conclusions
```

---

### Layer 2: Voice Markers (What makes it sound like them?)

**Objective**: Identify their unique sonic fingerprint.

**Elements to catalog:**

1. **Signature Phrases**
   ```
   - Document exact phrases that appear repeatedly
   - Note frequency across samples
   - Context of usage (opening, closing, emphasis)
   - Example: Murrow's "This is London" (26/30 broadcasts)
   ```

2. **Pronoun Usage**
   ```
   For each sample:
   - Count: I, you, we, they
   - Calculate pronoun density (per 100 words)
   - Note perspective shifts
   - Example: Pyle heavy "you" (direct address), Murrow heavy "I" (witness)
   ```

3. **Qualifiers and Hedges**
   ```
   - List all hedging words: maybe, probably, I think, perhaps, seems
   - Calculate frequency
   - Context of usage (admits ignorance, shows uncertainty)
   - Example: Pyle "I don't know" / "I'm not sure" in 70% of samples
   ```

4. **Direct Address Patterns**
   ```
   - When do they speak directly to reader?
   - How often? (every paragraph, every page, rarely)
   - Purpose: pull reader in, create intimacy, emphasize point
   - Example: Pyle "You can feel..." / "You could see..."
   ```

5. **Tonal Consistency**
   ```
   - Map emotional register: formal, conversational, intimate, clinical
   - Note register changes (when/why they shift tone)
   - Identify tonal boundaries (what tone they never use)
   - Example: Pyle=conversational friend, Murrow=formal witness
   ```

6. **Vocabulary Level**
   ```
   - Note use of jargon vs. plain language
   - Technical terms frequency
   - Complexity of vocabulary (reading level)
   - Deliberate simplicity vs. natural complexity
   ```

**Output**: Voice profile with examples
```markdown
## Voice Profile: [Writer Name]

**Signature Phrases**:
- "[Exact phrase]" - appears in X/N samples (context: Y)
- "[Another phrase]" - appears in Y/N samples (context: Z)

**Pronoun Usage** (per 100 words average):
- I: X times
- You: Y times
- We: Z times
- Typical perspective: [first-person witness / second-person address / etc.]

**Qualifiers/Hedges**:
- Most common: "[maybe]" (X% of samples)
- Pattern: Used when [admitting ignorance / showing uncertainty]
- Example: "[exact quote showing usage]"

**Direct Address**:
- Frequency: [every paragraph / occasionally / rarely]
- Purpose: [pull reader into scene / create intimacy]
- Example: "[exact quote]"

**Tonal Register**: [Conversational / Formal / Intimate / Clinical]
- Boundaries: Never uses [specific tone]
- Shifts: Changes tone when [specific circumstance]

**Vocabulary**:
- Reading level: [grade level or complexity descriptor]
- Jargon: [frequent / occasional / never]
- Deliberate simplicity: [Yes/No] - evidence: [example]
```

---

### Layer 3: Content Patterns (What do they show/tell?)

**Objective**: Document how they handle information and narrative.

**Elements to analyze:**

1. **Observation Types**
   ```
   For each sample, categorize observations as:
   - Physical details (what they see, hear, smell, touch)
   - Emotional states (their feelings or others' feelings)
   - Abstract concepts (ideas, meanings, interpretations)

   Calculate ratios:
   - Physical:Emotional:Abstract (e.g., 70:20:10)
   - Concrete vs. Abstract tendency
   ```

2. **Conflict Handling**
   ```
   When disagreements/arguments appear:
   - Do they resolve? (Yes/No/Sometimes)
   - Do they show both sides? (Yes/No/One-sided)
   - How much detail? (Dialogue, summary, implications)
   - Emotional temperature? (Hot/Cool/Clinical)

   Example: Pyle shows unresolved arguments (Patton vs. Rickover)
   ```

3. **Source Attribution**
   ```
   How do they credit information?
   - Named sources with full context
   - Anonymous sources ("someone said")
   - Personal observation ("I watched")
   - Unsourced assertions

   Calculate attribution ratio
   ```

4. **Technical Detail Level**
   ```
   When technical information appears:
   - Specific numbers and measurements? (Yes/No/Sometimes)
   - Technical terminology? (Explained/Unexplained/Avoided)
   - Level of precision? (High/Medium/Low/Deliberately vague)

   Example: Pyle avoids technical jargon, uses visual descriptions
   ```

5. **Emotional Range**
   ```
   Catalog emotions expressed across corpus:
   - Anger: How often? How expressed?
   - Sadness: How often? How expressed?
   - Hope: How often? How expressed?
   - Confusion: How often? How expressed?
   - Fear: How often? How expressed?

   For each emotion:
   - Stated directly or shown through details?
   - Reserved or openly expressed?
   ```

6. **Narrative Structure**
   ```
   How do they tell stories?
   - Chronological vs. fragmented
   - Single thread vs. multiple threads
   - Linear vs. circular
   - Complete vs. deliberately incomplete
   ```

**Output**: Content handling profile
```markdown
## Content Profile: [Writer Name]

**Observation Ratio**:
- Physical details: X%
- Emotional states: Y%
- Abstract concepts: Z%
- Tendency: [Concrete/Balanced/Abstract]

**Conflict Handling**:
- Resolution: [Always/Sometimes/Never]
- Both sides shown: [Yes/No]
- Detail level: [Extensive/Moderate/Minimal]
- Temperature: [Hot/Cool/Clinical]
- Example: "[specific instance from sample]"

**Source Attribution**:
- Named sources: X%
- Anonymous: Y%
- Personal observation: Z%
- Unsourced: W%

**Technical Details**:
- Precision: [High/Medium/Low/Vague]
- Jargon: [Frequent/Occasional/Never]
- Explanation: [Always/Sometimes/Never]
- Example: "[how they handle technical subject]"

**Emotional Range**:
- Most expressed: [emotion] (X samples) - [how expressed]
- Least expressed: [emotion] (Y samples)
- Avoided: [emotion] - never appears
- Style: [Direct statement / Shown through details]

**Narrative Structure**:
- Default: [Chronological/Fragmented/etc.]
- Completeness: [Complete stories / Deliberately incomplete]
- Threading: [Single/Multiple]
```

---

### Layer 4: Anti-Patterns (What do they NEVER do?)

**Objective**: Define voice boundaries by identifying what breaks their style.

**Elements to document:**

1. **Forbidden Phrases**
   ```
   Track phrases that:
   - Are common in AI writing but never appear in their work
   - Are common in contemporary writing but foreign to their style
   - Violate their tonal register

   Sources:
   - Known AI markers ("Here's where it gets interesting")
   - Modern business speak ("circle back", "touch base")
   - Academic jargon they avoided
   ```

2. **Structural Taboos**
   ```
   Structural patterns that never appear:
   - Perfect parallel structure (three equal items)
   - Mechanical bullet lists
   - Numbered step-by-step instructions
   - Formulaic openings/closings

   Note: Absence across ALL samples = probable taboo
   ```

3. **Tonal Violations**
   ```
   Tones/registers that never appear:
   - Clinical detachment (if they're intimate)
   - Casual slang (if they're formal)
   - Overly formal (if they're conversational)
   - Sarcasm/cynicism (if they're earnest)

   Document: What emotional register is out of bounds?
   ```

4. **Content Mistakes**
   ```
   Content approaches they never use:
   - Summary statements at end
   - Meta-commentary about the writing itself
   - Explicit moral conclusions
   - Explaining jokes/observations
   - Stating themes directly
   ```

5. **Rhythm Violations**
   ```
   Rhythmic patterns they avoid:
   - Perfect consistency (all sentences same length)
   - Mechanical alternation (short-long-short-long)
   - Run-on sentences without purpose
   - Choppy fragments without buildup
   ```

**Method**: Negative evidence
```
1. Read authentic sample
2. Note what ISN'T there (especially common patterns you expect)
3. Check across multiple samples (absence = pattern)
4. Document with counter-examples (show what they do instead)
```

**Output**: Anti-pattern catalog
```markdown
## Anti-Patterns: [Writer Name]

**Forbidden Phrases** (never appear in N samples):
- ❌ "[AI phrase]" (appears: 0/N samples)
  - Why: [violates conversational tone / too corporate]
  - Instead: [what they do say]

**Structural Taboos**:
- ❌ Perfect three-point lists (appears: 0/N samples)
  - Why: [too mechanical for their organic style]
  - Instead: [irregular listing or descriptive flow]

**Tonal Violations**:
- ❌ [Specific tone] (never used)
  - Why: [outside their emotional register]
  - Boundaries: [stays within X range]

**Content Mistakes**:
- ❌ Summary conclusions (appears: 0/N samples)
  - Why: [trusts reader to draw conclusions]
  - Instead: [ends with detail or action]

**Rhythm Violations**:
- ❌ [Specific pattern] (never used)
  - Why: [sounds mechanical]
  - Instead: [their actual rhythm pattern]

**Testing Negative Evidence**:
- Read generated content
- Check for anti-patterns
- If ANY present → fails authenticity test
```

---

## Extraction Workflow

### Phase 1: Inventory (First Pass)

1. Read all samples once through for overall impression
2. Take rough notes on obvious patterns
3. Identify themes/topics covered
4. Note emotional range demonstrated
5. Get "feel" for the voice

**Output**: Overview document with initial impressions

### Phase 2: Structural Analysis (Second Pass)

1. Count sentences, measure lengths
2. Analyze paragraph structures
3. Document opening/closing techniques
4. Map rhythm patterns
5. Enter data into spreadsheet

**Output**: Quantitative structural profile

### Phase 3: Voice Analysis (Third Pass)

1. Highlight all signature phrases
2. Count pronouns and qualifiers
3. Mark direct address moments
4. Assess tonal consistency
5. Note vocabulary patterns

**Output**: Voice profile with examples

### Phase 4: Content Analysis (Fourth Pass)

1. Categorize observations (physical/emotional/abstract)
2. Analyze conflict handling
3. Document source attribution
4. Assess technical detail approach
5. Map emotional range

**Output**: Content handling profile

### Phase 5: Anti-Pattern Identification (Fifth Pass)

1. List what you expected but didn't find
2. Note common patterns that never appear
3. Document tonal boundaries
4. Identify structural taboos
5. Cross-reference with AI/contemporary writing

**Output**: Anti-pattern catalog

### Phase 6: Synthesis

1. Combine all four layers
2. Identify universal patterns (appear in 80%+ samples)
3. Identify strong patterns (appear in 50-80% samples)
4. Identify contextual patterns (appear in specific situations)
5. Prioritize for guideline creation

**Output**: Complete pattern library ready for guidelines

---

## Quality Checks

**Pattern Validity Tests:**

1. **Frequency Test**: Pattern must appear in 3+ samples minimum
2. **Consistency Test**: Pattern must be consistent across samples (not contradicted)
3. **Measurability Test**: Pattern must be observable/quantifiable
4. **Actionability Test**: Pattern must be translatable to "do this" instruction
5. **Distinctiveness Test**: Pattern must help distinguish this writer from others

**Common Mistakes to Avoid:**

❌ **Vague patterns**: "Writes authentically" (not measurable)
✅ **Specific patterns**: "Uses second-person address 2-3 times per 500 words"

❌ **Subjective patterns**: "Feels emotional" (not actionable)
✅ **Objective patterns**: "Shows exhaustion through physical details (rubbing eyes, cold coffee) not stated feelings"

❌ **Cherry-picked patterns**: "Ends with hope" (found in 1 sample)
✅ **Validated patterns**: "Ends with anticlimax" (found in 12/15 samples)

❌ **Generic patterns**: "Uses descriptive language" (everyone does)
✅ **Distinctive patterns**: "23% one-sentence paragraphs vs. typical 5-8%"

---

## Tools and Templates

**Sentence Length Tracker** (spreadsheet):
```
Sample | Sentence | Length | Type
001    | 1        | 15     | Statement
001    | 2        | 3      | Fragment
001    | 3        | 42     | Compound
```

**Pattern Frequency Log**:
```
Pattern | Sample 001 | Sample 002 | Sample 003 | Total | %
Second-person | Yes (3x) | Yes (2x) | No | 5 | 67%
Anticlimax end | Yes | Yes | No | 2 | 67%
```

**Voice Marker Highlighter**:
```
- Highlight signature phrases in yellow
- Highlight direct address in green
- Highlight qualifiers in blue
- Highlight unique vocabulary in pink
```

---

## From Patterns to Guidelines

Once extraction is complete, convert patterns into actionable guidelines:

**Universal Pattern** (80%+ samples) → **Tier 1 Non-Negotiable**
- Example: "Never use summary conclusions" → Checklist item

**Strong Pattern** (50-80% samples) → **Tier 2 Strong Pattern**
- Example: "Use one-sentence paragraphs for emphasis" → Guideline

**Contextual Pattern** (20-50% samples) → **Tier 3 Flourish**
- Example: "Compound 'and' chains when witnessing action" → Technique

**Anti-Pattern** (0% samples) → **Tier 1 Forbidden**
- Example: "Never use 'Here's where it gets interesting'" → Checklist item

---

## Documentation Standards

Each pattern must include:

1. **Pattern name**: Clear, descriptive label
2. **Frequency**: X/N samples, Y% occurrence
3. **Examples**: 2-3 quotes showing pattern in action
4. **Context**: When/where pattern appears
5. **Purpose**: Why this pattern serves their voice
6. **Actionable rule**: How to apply pattern in new content

**Example Documentation:**
```markdown
### Pattern: Admitted Ignorance

**Frequency**: 11/15 samples (73%)

**Examples**:
- "I don't know who. But I heard Montgomery say..." (Sample 007)
- "Not sure what. But suddenly..." (Sample 009)
- "Maybe I'll understand tomorrow. Maybe not." (Sample 012)

**Context**: Appears when:
- Incomplete information available
- Witnessing confusion
- Ending pieces without resolution

**Purpose**:
- Builds trust through honesty
- Creates intimacy with reader
- Avoids false authority

**Actionable Rule** (Tier 2):
- Use admitted ignorance 1-2 times per 1000 words
- When information is genuinely incomplete
- Especially effective in endings
- Avoid overuse (loses power)
```

---

## Next Steps

After extraction complete:
1. Create `{name}-patterns.md` with all four layers
2. Create `{name}-guidelines.md` with three-tier system
3. Test guidelines on sample content
4. Refine based on validation results
5. Document in `{name}-validation-history.md`

---

**Extraction is the foundation. Guidelines are the tool. Validation is the proof.**
