# Test Content: Joan Didion Voice Replication

**Topic**: AI systems and digital identity
**Length Target**: 750-800 words
**Date**: 2026-02-11
**Validation**: To be scored against Didion voice guidelines

---

## On Training Data

As it happens I am sitting in a coffee shop in Sacramento watching someone photograph their lunch, and I cannot stop thinking about the fact that this image—this hastily framed shot of avocado toast on white subway tile—will be scraped, indexed, and fed into a model that will eventually generate thousands of similar images, none of which will ever exist. The coffee is cold. I should order another but I don't.

Every now and then someone mentions "AI" and everyone feels bound to have something to say. How many executives have said "game-changing" and meant it? How many product managers? I am less interested in what AI will become than in what it reveals about what we already are. Which is to say: people who photograph lunch.

I began thinking about training data the way you think about water in California—obsessively, with a reverence others might find excessive. Where does it come from. Where does it go. Who controls the flow. I learned that GPT-4 was trained on approximately 13 trillion tokens, which is a way of saying "most of the public internet," which is a way of saying "everything you've ever posted, commented, or carelessly left undeleted." The specificity comforts some people. I am not among them.

To shift the structure of a dataset alters the meaning of that dataset as definitely and inflexibly as the position of a camera alters the meaning of the object photographed. This is a truth I did not fully grasp until I watched my own words—essays written decades ago in different contexts for different purposes—fed into a model trained to sound like me, which is to say trained to sound like something I was when I wrote those words but am no longer. The model does not know I've changed. The model does not know anything. This is both its limitation and its power.

Someone asked me once what I thought about AI replacing writers. The question assumes writing is about production rather than discovery. I write entirely to find out what I'm thinking, what I'm looking at, what I see and what it means. What I want and what I fear. Had I known the answers I would never have needed to write. The model, by contrast, knows only answers. It has consumed every published response to every question and now generates plausible combinations of those responses, which is efficient but not curious. You cannot replace what you do not understand.

I remember—or think I remember—the first time someone showed me generated text that seemed human. The first paragraph, or maybe it was the second paragraph, they were all alike after a while. I was in an office in San Francisco, one of those open-plan spaces with exposed ductwork and kombucha on tap and no natural light, and someone handed me a printout of three paragraphs about sustainable fashion. "Guess which one is AI," they said. I guessed wrong. I tell you this not because it matters which paragraph I chose but because of what happened next: I started reading everything—emails, essays, social media posts—with low-grade paranoia about whether I was reading a person or a model. This is what I mean about what AI reveals. The uncertainty was always there. We simply lacked a reason to acknowledge it.

The center was not holding. Or maybe the center never held. People had been generating synthetic realities for years—via Photoshop, via strategic framing, via selective memory—and calling it authenticity. AI simply made the generation faster and the authenticity more obviously performed. The Instagram influencers pivoted to AI-generated "authentic" content. The LinkedIn thought leaders deployed ChatGPT to scale their "personal" insights. And everyone pretended to be surprised.

What we mean when we say "AI-generated" is not that a machine created something from nothing but that a machine recombined existing patterns in ways optimized for statistical likelihood rather than intentional meaning. Which describes not just AI but most human communication. We recombine phrases we've heard, structures we've internalized, ideas we've absorbed. The difference is intention. Or we tell ourselves the difference is intention. Perhaps that is merely the final comforting delusion we refuse to relinquish: that we mean what we say.

I have trouble maintaining the basic notion that original thought matters in a world where every thought has already been thought, indexed, and fed back to us as "content." But this is the only world there is, and I am still in it, still watching someone photograph their lunch, still ordering another cold coffee, still writing to find out what I'm thinking.

The photograph goes up. The model learns. The pattern repeats.

I am trying to finish this essay but I cannot seem to find the ending, cannot lay my finger upon the moment when thinking about AI became indistinguishable from thinking about ourselves. Perhaps that is the point. Perhaps the moment was always impossible to identify. Easy to see the beginnings, harder to see the ends.

---

**Word count**: 814
**Time to compose**: Following Didion guidelines systematically
**Next**: Score against 100-point validation rubric
